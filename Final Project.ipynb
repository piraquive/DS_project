{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Professor Research and Student Success\n",
    "\n",
    "## By Diego Piraquive, James Firpo and Trevor Teerlink\n",
    "\n",
    "\n",
    "The University of Utah is known for its excellence in academic research, and claims \"Research is a major component in the life of the U benefiting students as well as the region. The University of Utah is ranked 47th in the U.S. and 87th in the world in the 2014 Academic Ranking of World Universities.\" - http://research.utah.edu/.  As 3 students who are wrapping up our senior year in mechanical engineering and Mathematics, we sometimes wonder how much University research REALLY benefits students.  Yes, of course we all feel that being involved in reserach is beneficial to our learning, but it often feels that professors are so devoted to research, that it reduces the time and energy put into teaching.  Sit in on some of these professors's classes, and you might find its not that they have a BAD teaching style, its just that theres NO teaching style.  It is very much a presentation of information, whith little transfer of enthusiasm.  \n",
    "\n",
    "The purpose of our project is to search for any correlations between the amount of time a professor spends on research, and detect if this has an effect on their students.  We have a suspicion that professors who are heavily involved in research, have less commitment to their students, which may be reflected through poorer student performance.\n",
    "\n",
    "We have two sources we are scraping from.  The OBIA (Office of Budget and Institutional Analysis), and a factory directory website, which contains links to every professor's Google Scholar account.  From the OBIA we will scrape classes, the class professor, and the class grades.  From the Faculty directory and google scholar links, we will attain an \"h-index\" for each professor.  The h-index is an author-level metric that attempts to measure both the productivity and citation impact of the publications of a scientist or scholar. The index is based on the set of the scientist's most cited papers and the number of citations that they have received in other publications.  We therefore find the h-index to be a good indicator of a professor's involvment in research, and their \"time spent away from teaching\".\n",
    "\n",
    "After the data is collected, we then use linear regression, and correlation matrices to analyze the relation between the h-index and student grades.  This was done for all the professors, and their respective classes in the Mechanical Engineering program.  \n",
    "\n",
    "In conclusion, we found that.................\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtaining h-index\n",
    "\n",
    "In the cell below, we demonstrate we can scrape a common faculty directory, https://mech.utah.edu/faculty/.\n",
    "The code builds two functions:  one function to get the h-index from google scholar, and the second function\n",
    "navigates to grab all the the google scholar urls from the faculty page.  We then employ these funcitons together to obtain the h-index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Jake Abbott', 28), ('Claire Acevedo', 9), ('Tim Ameel', 27), ('Rebecca Brannon', 17), ('Marc Calaf', 9), ('Jiyoung Chang', 11), ('Brittany Coats', 12), ('Michael Czabaj', 9), ('Mathieu Francoeur', 21), ('Henry Fu', 17), ('Bruce Gale', 34), ('Owen Kingstedt', 4), ('Yong Lin Kong', 7), ('Kam K. Leang', 31), ('Tommaso Lenzi', 22), ('Stephen Mascaro', 17), ('Patrick McMurtry', 26), ('Sanford G. Meek', 21), ('Andrew Merryweather', 11), ('Mark A. Minor', 20), ('Ken Monson', 12), ('Steven Naleway', 10), ('Pania Newell', 8), ('Eric Pardyjak', 26), ('Keunhan (Kay) Park', 18), ('Bart Raeymaekers', 15), ('Shad Roundy', 20), ('Amanda Smith', 10), ('Ashley Spear', 5), ('Rob Stoll', 11), ('Wenda Tan', 7), ('Roseanne Warren', 6)]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "import urllib.request\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "\n",
    "def get_hindex(url):\n",
    "    scholar_soup = BeautifulSoup(urllib.request.urlopen(url), 'lxml')\n",
    "    return int(scholar_soup.findAll(\"td\", {\"class\": \"gsc_rsb_std\"})[2].text)\n",
    "\n",
    "\n",
    "\n",
    "def get_prof_scores():\n",
    "    soup = BeautifulSoup(urllib.request.urlopen(\"https://mech.utah.edu/faculty/\"), 'lxml')\n",
    "\n",
    "    for row in soup.find(\"table\", {\"id\": \"tablepress-7\"}).findAll(\"tr\"):\n",
    "        tds = row.findAll(\"td\")\n",
    "        if len(tds) == 0:\n",
    "            continue\n",
    "\n",
    "        _, name, body, _ = tds\n",
    "        link = body.find(\"a\")\n",
    "        if not link:\n",
    "            continue\n",
    "        url = link[\"href\"]\n",
    "      \n",
    "\n",
    "        yield (name.find(\"strong\").text.strip(), get_hindex(url))\n",
    "\n",
    "prof_scores = list(get_prof_scores())\n",
    "\n",
    "print(prof_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Obtain class and grades data from OBIA files\n",
    "Now we have a list of all the Mechanical Engineering professors and their h-index score.  \n",
    "This is a very handy metric to show how dedicated a professor is to research.\n",
    "\n",
    "Below, we begin assembling the data from the OBIA website, and cleaning as we go.  We first grab CSV files from the site, and then begin dropping un-wanted columns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import urllib.request\n",
    "\n",
    "import time\n",
    "import pandas as pd\n",
    "import scipy as sc\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "import statsmodels.formula.api as sm\n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "plt.style.use('ggplot')\n",
    "%matplotlib inline  \n",
    "plt.rcParams['figure.figsize'] = (10, 6) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getgrades(csv1):\n",
    "    grades1=pd.read_csv(csv1, encoding=\"utf8\")\n",
    "    #grades2=pd.read_csv(csv2, encoding=\"utf8\")\n",
    "    #grds=[grades1, grades2]\n",
    "    #grades=pd.concat(grds,ignore_index=True)\n",
    "    i=0\n",
    "    #grades=grades.reset_index(drop=True)\n",
    "    hc=grades1['sumHeadcount']\n",
    "    while i < len(hc):\n",
    "        if hc[i]== 'ds':\n",
    "            grades1=grades1.drop(i, axis=0)\n",
    "        i+=1\n",
    "    grades=grades1.reset_index(drop=True)\n",
    "    return(grades)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def combinegrades(grades):\n",
    "    i=1\n",
    "    n=2\n",
    "    gradesclean=pd.DataFrame([],columns=['Cat. #', 'Sec.', 'Subject', 'A', 'B', 'C', 'D', 'E', 'W', 'Other'])\n",
    "    gradesclean=gradesclean.append({'Cat. #':grades['Catalog Num'][0], 'Sec.':grades['Section'][0], 'Subject':grades['Subject'][0], 'A':0, 'B':0, 'C':0, 'D':0,\n",
    "                                    'E':0, 'W':0, 'Other':0}, ignore_index=True)\n",
    "    gradesclean[grades['Grade Group'][0]][0]=grades['sumHeadcount'][0]\n",
    "    while i<len(grades['sumHeadcount']):\n",
    "        if grades['Subject'].iloc[i]==gradesclean['Subject'].iloc[-1]:\n",
    "            if grades['Catalog Num'].iloc[i]==gradesclean['Cat. #'].iloc[-1]:\n",
    "                fail=0\n",
    "                for m in range(1,n):\n",
    "                    if grades['Section'].iloc[i]==gradesclean['Sec.'].iloc[-m]:\n",
    "                        gradesclean[grades['Grade Group'].iloc[i]].iat[-m]=grades['sumHeadcount'].iloc[i]\n",
    "                        break\n",
    "                    fail+=1\n",
    "                if fail==n-1:\n",
    "                    n+=1\n",
    "                    gradesclean=gradesclean.append({'Cat. #':grades['Catalog Num'].iloc[i],\n",
    "                                                    'Sec.':grades['Section'].iloc[i],\n",
    "                                                    'Subject':grades['Subject'].iloc[i], 'A':0, 'B':0,\n",
    "                                                    'C':0,'D':0, 'E':0, 'W':0, 'Other':0}, ignore_index=True)\n",
    "                    gradesclean[grades['Grade Group'].iloc[i]].iat[-1]=grades['sumHeadcount'].iloc[i]\n",
    "            else:\n",
    "                n=2\n",
    "                gradesclean=gradesclean.append({'Cat. #':grades['Catalog Num'].iloc[i], 'Sec.':grades['Section'].iloc[i],\n",
    "                                                'Subject':grades['Subject'].iloc[i], 'A':0, 'B':0,\n",
    "                                                'C':0,'D':0, 'E':0, 'W':0, 'Other':0}, ignore_index=True)\n",
    "                gradesclean[grades['Grade Group'].iloc[i]].iat[-1]=grades['sumHeadcount'].iloc[i]\n",
    "        else:\n",
    "            n=2\n",
    "            gradesclean=gradesclean.append({'Cat. #':grades['Catalog Num'].iloc[i], 'Sec.':grades['Section'].iloc[i],\n",
    "                                            'Subject':grades['Subject'].iloc[i], 'A':0, 'B':0,\n",
    "                                            'C':0,'D':0, 'E':0, 'W':0, 'Other':0}, ignore_index=True)\n",
    "            gradesclean[grades['Grade Group'].iloc[i]].iat[-1]=grades['sumHeadcount'].iloc[i]\n",
    "        i+=1\n",
    "    return(gradesclean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "File b'MEN F17.csv' does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-2c4590ab9447>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mcleaned\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m<\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0megrades\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mgradess\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgetgrades\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0megrades\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mgradescleans\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcombinegrades\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradess\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mcleaned\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgradescleans\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-ce1188e1486d>\u001b[0m in \u001b[0;36mgetgrades\u001b[0;34m(csv1)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mgetgrades\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcsv1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mgrades1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcsv1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"utf8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;31m#grades2=pd.read_csv(csv2, encoding=\"utf8\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;31m#grds=[grades1, grades2]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m#grades=pd.concat(grds,ignore_index=True)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, skip_footer, doublequote, delim_whitespace, as_recarray, compact_ints, use_unsigned, low_memory, buffer_lines, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    653\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    654\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 655\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    656\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    657\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    403\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    404\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 405\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    406\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    407\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    762\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    763\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 764\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    765\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m    983\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 985\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    986\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    987\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'python'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1603\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'allow_leading_cols'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_col\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1604\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1605\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1607\u001b[0m         \u001b[0;31m# XXX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__ (pandas/_libs/parsers.c:4209)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source (pandas/_libs/parsers.c:8873)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: File b'MEN F17.csv' does not exist"
     ]
    }
   ],
   "source": [
    "egrades=['MEN F17.csv','MEN S17.csv','MEN F16.csv','MEN S16.csv','MEN F15.csv','MEN S15.csv','MEN F14.csv','MEN S14.csv','MEN F13.csv']\n",
    "i=0\n",
    "cleaned=[0,0,0,0,0,0,0,0,0]\n",
    "while i<len(egrades):\n",
    "    gradess=getgrades(egrades[i])\n",
    "    gradescleans=combinegrades(gradess)\n",
    "    cleaned[i]=gradescleans\n",
    "    i+=1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Relating professor names to class numbers\n",
    "We used the course catalog to scrape course numbers and professor names, in a similar fasion to how we did in lecture. This made it possible to connect course numbers with their corresponding professor.  To caputre all the classes in the catalog, we needed to scroll through the entire page, which prevented us from scraping.  We first tried using a program called Selenium, but quickly learned we needed java experience to use it.  To solve the problem, we manually downloaded, and modified the html code to extract all the ME EN courses. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def instruct(excel, working):\n",
    "    F17t=pd.read_excel(excel)\n",
    "    i=0\n",
    "    working['Instructor']= ['ds']*len(working['A'])\n",
    "    while i<len(working['A']):\n",
    "        m=0\n",
    "        while m<len(F17t['Sec.']):\n",
    "            if working['Cat. #'].iloc[i] == F17t['Cat. #'].iloc[m]:\n",
    "                if working['Sec.'].iloc[i] == F17t['Sec.'].iloc[m]:\n",
    "                    working.at[i,'Instructor']= F17t['Instructor'].iloc[m].partition(',')[0]\n",
    "            m+=1\n",
    "        i+=1\n",
    "    i=0\n",
    "    while i<len(working['A']):\n",
    "        if working['Instructor'].iloc[i] == 'ds':\n",
    "            working=working.drop(i, axis=0)\n",
    "        i+=1\n",
    "    working=working.reset_index(drop=True)\n",
    "    return(working)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "excels=['F17_meen_classes.xlsx','S17_meen_classes.xlsx','F16_meen_classes.xlsx',\n",
    "        'S16_meen_classes.xlsx','F15_meen_classes.xlsx','S15_meen_classes.xlsx',\n",
    "        'F14_meen_classes.xlsx','S14_meen_classes.xlsx','F13_meen_classes.xlsx']\n",
    "insts=[]\n",
    "i=0\n",
    "while i<9:\n",
    "    insts.append(instruct(excels[1],cleaned[1]))\n",
    "    i+=1\n",
    "insts[0]['Sem']= ['F17']*len(insts[0]['A'])\n",
    "insts[1]['Sem']= ['S17']*len(insts[1]['A'])\n",
    "insts[2]['Sem']= ['F16']*len(insts[2]['A'])\n",
    "insts[3]['Sem']= ['S16']*len(insts[3]['A'])\n",
    "insts[4]['Sem']= ['F15']*len(insts[4]['A'])\n",
    "insts[5]['Sem']= ['S15']*len(insts[5]['A'])\n",
    "insts[6]['Sem']= ['F14']*len(insts[6]['A'])\n",
    "insts[7]['Sem']= ['S14']*len(insts[7]['A'])\n",
    "insts[8]['Sem']= ['F13']*len(insts[8]['A'])\n",
    "finished=pd.concat(insts,ignore_index=True)\n",
    "mask=finished['Instructor'] != 'ds'\n",
    "finished=finished[mask]\n",
    "finished=finished.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hscore=[('ABBOTT', 28), ('ACEVDO', 8), ('AMEEL', 27), ('BRANNON', 17),\n",
    " ('CALAF', 9), ('CHANG', 11), ('COATS', 12), ('CZABAJ', 9),\n",
    " ('FRANCOEUR', 21), ('FU', 17), ('GALE', 34), ('KINGSTEDT', 4),\n",
    " ('KONG', 6), ('LEANG', 31), ('LENZI', 22), ('MASCARO', 17),\n",
    " ('MCMURTRY', 26), ('MEEK', 21), ('MERRYWEATHER', 11), ('MINOR', 21),\n",
    " ('MONSON', 12), ('NALEWAY', 10), ('NEWELL', 8), ('PARDYJAK', 26), \n",
    " ('PARK', 18), ('RAEYMAEKERS', 15), ('ROUNDY', 20), ('SMITH', 10),\n",
    " ('SPEAR', 5), ('STOLL', 11), ('TAN', 7), ('WARREN', 6)]\n",
    "i=0\n",
    "finished['h-score']= ['ds']*len(finished['A'])\n",
    "while i < len(finished['Sem']):\n",
    "    for m in hscore:\n",
    "        if m[0] == finished['Instructor'].iloc[i]:\n",
    "            finished.at[i,'h-score']= m[1]\n",
    "    i+=1\n",
    "mask=finished['h-score'] != 'ds'\n",
    "finished=finished[mask]\n",
    "finished=finished.reset_index(drop=True)\n",
    "finished"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data analysis through linear regression and correlation\n",
    "We have now collected all relevant class, professor, and student information.  We perform linear regression to uncover the existance of any possible correlations between h-index and student scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#libraries\n",
    "import scipy as sc\n",
    "from scipy.stats import norm\n",
    "\n",
    "import pandas as pd\n",
    "import statsmodels.formula.api as sm\n",
    "from sklearn import linear_model\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline  \n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib import cm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#read in cleaned up data\n",
    "data = pd.read_csv('h-scored.csv')\n",
    "#drop the old index and subject since they're all ME\n",
    "data = data.drop(['Unnamed: 0', 'Subject','Sec.','Cat. #','Sem'],axis = 1)\n",
    "data['h_score']=data['h-score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#In order to later use the OLS \n",
    "data = data.drop(['h-score'],axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "data['# of Students'] = data['A']+data['B']+data['C']+data['D']+data['E']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data['Average_GPA'] = ((data['A']*4.0)+(data['B']*3.0)+(data['C']*2.0)+(data['D']*1)+(data['E']*0))/(data['# of Students'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation Matrix\n",
    "This will show visually how the h-index affects student scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#create a dataframe of the two variables we are interested in their coorelation\n",
    "relevant_data = data[['h_score','Average_GPA']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#ex\n",
    "print(relevant_data.corr())\n",
    "pd.plotting.scatter_matrix(relevant_data, figsize=(10, 10), diagonal='kde')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Grades_ols = sm.ols(formula=\"Average_GPA ~ h_score\", data=relevant_data).fit()\n",
    "Grades_ols.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.scatter(x=data['h_score'],y=data['Average_GPA'],c='b',marker='s',label='GPA')\n",
    "plt.legend(numpoints=1,loc=4)\n",
    "plt.plot(data['Average_GPA'],Grades_ols.predict(),c='r',linewidth=1)\n",
    "\n",
    "plt.xlabel('Average Grade Point Average')\n",
    "plt.ylabel('h-score index')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Using our model, this plot shows a predection of student GPA based on the h-score of a professor.  It is evident that the model cannont accurately predict student scores given a professor's h-index."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CONCLUSION\n",
    "\n",
    "From the analysis, we can see that the h-index, does not conclusively affect student scores quite as strongly as we had hoped, with a correlation of negative %34.  This means, essentially, that only 34% of the data supports our hypothesis that the averages grades are lower for a class whose professor spends more time doing research.  Being that random data has an expected correlation of 50%, we can conclude that this data does not support that a conclusion can be made.  Unfortunately we were not able to prove our initial hypothessis, but through the data analysis, we can propose another hypothesis that a professor's involvment in research does not academicly affect student scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
